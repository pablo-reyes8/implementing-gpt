{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-18T05:26:41.860791Z",
     "iopub.status.busy": "2025-11-18T05:26:41.860457Z",
     "iopub.status.idle": "2025-11-18T05:27:29.471567Z",
     "shell.execute_reply": "2025-11-18T05:27:29.470536Z",
     "shell.execute_reply.started": "2025-11-18T05:26:41.860762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 4007\n",
      "})\n",
      "Cargando tokenizer desde owt10k_tokenizer.json...\n",
      "Tokenizando y concatenando textos...\n",
      "Total de tokens en este split: 11,175,296\n",
      "Número de secuencias: 43,483\n",
      "Forma inputs:  torch.Size([43483, 256])\n",
      "Forma targets: torch.Size([43483, 256])\n",
      "Tokenizando y concatenando textos...\n",
      "Total de tokens en este split: 4,808,361\n",
      "Número de secuencias: 18,709\n",
      "Forma inputs:  torch.Size([18709, 256])\n",
      "Forma targets: torch.Size([18709, 256])\n",
      "Batch x shape: torch.Size([64, 256])\n",
      "Batch y shape: torch.Size([64, 256])\n",
      "Texto ejemplo (primer sample de x):\n",
      "premier.ticketek.com.au\n",
      "\n",
      "■ make beautiful music with elton john and his band\n",
      "\n",
      "media_camera elton john performs in adelaide on january 28\n",
      "\n",
      "the legendary sir elton john is playing all the hits from his brilliant career spanning five decades including songs from his classic album goodbye yellow brick road which recently celebrated its 40th anniversary.\n",
      "\n",
      "details: adelaide entertainment centre, tuesday, january 28, 7pm. visit www.theaec.net\n",
      "\n",
      "■ catch your idol\n",
      "\n",
      "see amercian idol finalist turned international star adam lambert in this intimate show as part of his the original high tour supported by 20-year-old new york artist melanie martinez.\n",
      "\n",
      "details: adelaide entertainment centre theatre, tuesday, december 15, 8pm. www.theaec.net\n",
      "\n",
      "■ sassy swizzle\n",
      "\n",
      "get ready for a brand new show jam-packed with acrobatics, cabaret and feisty entertainment. get ready for club swizzle! if you’re looking for a fun and fantastic night out, then this show is not one to be missed. suitable for ages 12 and over.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_small_data import *\n",
    "\n",
    "DATASET_NAME   = \"Ankursingh/openwebtext_10K\"\n",
    "DATASET_CONFIG = \"plain_text\"   # config por defecto del dataset\n",
    "VOCAB_SIZE = 16000         \n",
    "MIN_FREQ  = 2\n",
    "BLOCK_SIZE   = 256  # Ventana de contexto         \n",
    "VAL_FRACTION   = 0.1\n",
    "TOKENIZER_PATH = Path(\"owt10k_tokenizer.json\")\n",
    "\n",
    "CPU_COUNT   = os.cpu_count() or 2\n",
    "BATCH_SIZE  = 64\n",
    "NUM_WORKERS  = 2 if CPU_COUNT <= 2 else min(4, CPU_COUNT - 1)             \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "train_loader, val_loader, tokenizer = create_dataloaders()\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "print(\"Batch x shape:\", x.shape) \n",
    "print(\"Batch y shape:\", y.shape) \n",
    "\n",
    "\n",
    "example_ids = x[0].tolist()\n",
    "text = tokenizer.decode(example_ids)\n",
    "print(\"Texto ejemplo (primer sample de x):\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:27:35.197853Z",
     "iopub.status.busy": "2025-11-18T05:27:35.197176Z",
     "iopub.status.idle": "2025-11-18T05:27:35.338039Z",
     "shell.execute_reply": "2025-11-18T05:27:35.336872Z",
     "shell.execute_reply.started": "2025-11-18T05:27:35.197818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 0 ===\n",
      "\n",
      "--- Ejemplo 0 ---\n",
      "Input IDs   (primeros 50): [138, 33, 2872, 401, 138, 138, 46, 294, 182, 505, 5295, 1505, 1704, 4402, 1209, 138, 138, 46, 294, 182, 505, 5295, 235, 1505, 1704, 335, 3488, 10375, 207, 2496, 3041, 4402, 17, 256, 2728, 943, 4617, 209, 9540, 3041, 4402, 3870, 234, 14057, 7731, 831, 4036, 209, 1456, 2571]\n",
      "Target IDs  (primeros 50): [33, 2872, 401, 138, 138, 46, 294, 182, 505, 5295, 1505, 1704, 4402, 1209, 138, 138, 46, 294, 182, 505, 5295, 235, 1505, 1704, 335, 3488, 10375, 207, 2496, 3041, 4402, 17, 256, 2728, 943, 4617, 209, 9540, 3041, 4402, 3870, 234, 14057, 7731, 831, 4036, 209, 1456, 2571, 204]\n",
      "Input texto (modelo VE):\n",
      "\"\\n> learn more\\n\\neuler hermes north america insurance company\\n\\neuler hermes is north america's largest provider of trade credit insurance. we offer both domestic and export credit insurance policies that insure clients against commercial and political risk\"\n",
      "Target texto (modelo DEBE predecir):\n",
      "\"> learn more\\n\\neuler hermes north america insurance company\\n\\neuler hermes is north america's largest provider of trade credit insurance. we offer both domestic and export credit insurance policies that insure clients against commercial and political risk in\"\n",
      "\n",
      "--- Ejemplo 1 ---\n",
      "Input IDs   (primeros 50): [138, 138, 449, 1705, 653, 6656, 241, 640, 9891, 17, 401, 998, 201, 178, 2809, 17, 138, 138, 9059, 15, 382, 477, 424, 1944, 11566, 6656, 34, 716, 15, 1460, 178, 2406, 201, 1464, 3231, 317, 11154, 2457, 12, 2671, 13151, 434, 869, 17, 204, 178, 12651, 16, 805, 2020]\n",
      "Target IDs  (primeros 50): [138, 449, 1705, 653, 6656, 241, 640, 9891, 17, 401, 998, 201, 178, 2809, 17, 138, 138, 9059, 15, 382, 477, 424, 1944, 11566, 6656, 34, 716, 15, 1460, 178, 2406, 201, 1464, 3231, 317, 11154, 2457, 12, 2671, 13151, 434, 869, 17, 204, 178, 12651, 16, 805, 2020, 254]\n",
      "Input texto (modelo VE):\n",
      "'\\n\\nindividual controls for every filter. more power to the user.\\n\\ngreat, so what about individual mask controls? well, having the chance to actually select (multiple) smart filters would help. in the mock-up below'\n",
      "Target texto (modelo DEBE predecir):\n",
      "'\\nindividual controls for every filter. more power to the user.\\n\\ngreat, so what about individual mask controls? well, having the chance to actually select (multiple) smart filters would help. in the mock-up below i'\n",
      "\n",
      "================== RESUMEN AUTORREGRESIVO ==================\n",
      "Total posiciones comparadas (y[:, :-1] vs x[:, 1:]): 16320\n",
      "Coincidencias: 16320\n",
      "Proporción de coincidencia (ideal ~1.0): 1.000000\n",
      "\n",
      "Distribución de primeros tokens (input vs target):\n",
      "\n",
      "Top 10 tokens más frecuentes en x[:, 0]  (primer token que VE el modelo):\n",
      "  id=  138 | freq=     3 | texto='\\n'\n",
      "  id=  175 | freq=     3 | texto=' a'\n",
      "  id=  207 | freq=     2 | texto=' of'\n",
      "  id=  376 | freq=     2 | texto=' will'\n",
      "  id=  178 | freq=     2 | texto=' the'\n",
      "  id=  201 | freq=     2 | texto=' to'\n",
      "  id= 7307 | freq=     1 | texto=' resource'\n",
      "  id=  247 | freq=     1 | texto=' it'\n",
      "  id=10104 | freq=     1 | texto=' perry'\n",
      "  id=  195 | freq=     1 | texto='or'\n",
      "\n",
      "Top 10 tokens más frecuentes en y[:, 0]  (primer token que DEBE predecir):\n",
      "  id=  178 | freq=     4 | texto=' the'\n",
      "  id=   17 | freq=     3 | texto='.'\n",
      "  id=  138 | freq=     2 | texto='\\n'\n",
      "  id=  393 | freq=     2 | texto=' \"'\n",
      "  id=  175 | freq=     2 | texto=' a'\n",
      "  id=   15 | freq=     2 | texto=','\n",
      "  id=   33 | freq=     1 | texto='>'\n",
      "  id=  884 | freq=     1 | texto=' 6'\n",
      "  id= 1100 | freq=     1 | texto='att'\n",
      "  id= 1167 | freq=     1 | texto=' rest'\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_utils import *\n",
    "\n",
    "  \n",
    "inspect_autoregressive_loader(train_loader, tokenizer,\n",
    "                              num_batches=1,  \n",
    "                              max_examples=2, \n",
    "                              max_tokens_print=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T06:33:10.129471Z",
     "iopub.status.busy": "2025-11-18T06:33:10.128631Z",
     "iopub.status.idle": "2025-11-18T06:33:10.579979Z",
     "shell.execute_reply": "2025-11-18T06:33:10.579198Z",
     "shell.execute_reply.started": "2025-11-18T06:33:10.129439Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "import torch, gc\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T05:52:10.512064Z",
     "iopub.status.busy": "2025-11-18T05:52:10.511275Z",
     "iopub.status.idle": "2025-11-18T06:21:26.993097Z",
     "shell.execute_reply": "2025-11-18T06:21:26.991554Z",
     "shell.execute_reply.started": "2025-11-18T05:52:10.512038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 2 GPUs con DataParallel\n",
      "[Epoch 1 | step  150/680 | global_step=150] train_loss=8.9753  ppl=7905.66  tok_acc=3.49%  tok/s=62,364\n",
      "[Epoch 1 | step  300/680 | global_step=300] train_loss=8.2705  ppl=3906.99  tok_acc=5.50%  tok/s=63,175\n",
      "[Epoch 1 | step  450/680 | global_step=450] train_loss=7.8397  ppl=2539.43  tok_acc=6.93%  tok/s=63,386\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: \" eldemar's royal treasury. their priorities during this time consisted of investigating the invasion forces, looking for possible signs of red robe, trying to track down the rest of the missing key pieces and figuring out some way to leave the time loop. of course, since actually retrieving even the known pieces of the key was impossible with their current skills, and they had no idea what kind\"\n",
      "REF: \"emar's royal treasury. their priorities during this time consisted of investigating the invasion forces, looking for possible signs of red robe, trying to track down the rest of the missing key pieces and figuring out some way to leave the time loop. of course, since actually retrieving even the known pieces of the key was impossible with their current skills, and they had no idea what kind of\"\n",
      "HYP: ',,, the,,\\n the, the was to,, the to the.. the, the to, the,,, the to the. to first. the first,.. the. to to the to the the first..\\n the. the the the,. the first to. the first. the. the first.. and the was the the to the of'\n",
      "[Epoch 1 | step  600/680 | global_step=600] train_loss=7.5426  ppl=1886.64  tok_acc=8.03%  tok/s=63,418\n",
      "Epoch 1 done | train_loss=7.4135  train_ppl=1658.14  train_tok_acc=8.55%\n",
      "[Epoch 2 | step  150/680 | global_step=830] train_loss=6.2898  ppl=539.04  tok_acc=13.37%  tok/s=62,978\n",
      "[Epoch 2 | step  300/680 | global_step=980] train_loss=6.2122  ppl=498.82  tok_acc=13.83%  tok/s=63,274\n",
      "[Epoch 2 | step  450/680 | global_step=1130] train_loss=6.1364  ppl=462.38  tok_acc=14.27%  tok/s=63,392\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: ' destination. there was no new cable record for the walking dead spinoff in its second week, but there was a potentially telling victory. while its 8.2 million total viewers and 4.1 rating last night was down -18% in total viewers and -16% in adults 18-49 from its record-shattering august 23 debut that garnered 10.1 million viewers and a'\n",
      "REF: '. there was no new cable record for the walking dead spinoff in its second week, but there was a potentially telling victory. while its 8.2 million total viewers and 4.1 rating last night was down -18% in total viewers and -16% in adults 18-49 from its record-shattering august 23 debut that garnered 10.1 million viewers and a 4'\n",
      "HYP: \",\\n the's a time-,, the first..,. the own-, and he's a few the the.\\n the own-\\n,, of, the,\\n., year, a to the, of the of, the the,. the.,year, the first.year--.,,. waso in,\\n,,, the year\"\n",
      "[Epoch 2 | step  600/680 | global_step=1280] train_loss=6.0681  ppl=431.85  tok_acc=14.66%  tok/s=63,452\n",
      "Epoch 2 done | train_loss=6.0334  train_ppl=417.13  train_tok_acc=14.86%\n",
      "[Epoch 3 | step  150/680 | global_step=1510] train_loss=5.6820  ppl=293.54  tok_acc=16.88%  tok/s=62,867\n",
      "[Epoch 3 | step  300/680 | global_step=1660] train_loss=5.6385  ppl=281.04  tok_acc=17.14%  tok/s=63,291\n",
      "[Epoch 3 | step  450/680 | global_step=1810] train_loss=5.5964  ppl=269.44  tok_acc=17.38%  tok/s=63,472\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: ' her. she headed to a south los angeles storage facility where they last stored their belongings.\\n\\nshe found her mother sitting on a garbage bag full of clothes.\\n\\n“khadijah’s here!” her sister jeanine yells. her mother’s face brightened.\\n\\nshe explained the details of her graduation, the bus route to get there and gave her'\n",
      "REF: '. she headed to a south los angeles storage facility where they last stored their belongings.\\n\\nshe found her mother sitting on a garbage bag full of clothes.\\n\\n“khadijah’s here!” her sister jeanine yells. her mother’s face brightened.\\n\\nshe explained the details of her graduation, the bus route to get there and gave her mother'\n",
      "HYP: ' her she said to her new court angeles,,, she were year in own to.\\n\\nthe said the \" to on the new,, of the,\\n\\n“iil,i,s first is\\n mother said-,ve,\\n mother,s mother her, her\\n\\n“ was that “ of her parentsuation of “ man,, the a, she her a'\n",
      "[Epoch 3 | step  600/680 | global_step=1960] train_loss=5.5536  ppl=258.18  tok_acc=17.64%  tok/s=63,533\n",
      "Epoch 3 done | train_loss=5.5330  train_ppl=252.89  train_tok_acc=17.77%\n",
      "Guardado checkpoint (cada 3 epochs) -> gptmini_owt10k.pt\n",
      "[Epoch 4 | step  150/680 | global_step=2190] train_loss=5.2710  ppl=194.62  tok_acc=19.35%  tok/s=63,515\n",
      "[Epoch 4 | step  300/680 | global_step=2340] train_loss=5.2379  ppl=188.28  tok_acc=19.57%  tok/s=63,366\n",
      "[Epoch 4 | step  450/680 | global_step=2490] train_loss=5.2096  ppl=183.01  tok_acc=19.77%  tok/s=63,484\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: ' been devised to the same effect.\\n\\nhe added that providing small- to medium-range planes manufactured by the same company played a central role in the government’s plan to rejuvenate iran’s air transportation fleet.\\n\\nakhoundi further emphasized that atr will start to deliver the planes that iran has purchased within the next few weeks.\\n\\nhe also stressed that'\n",
      "REF: ' devised to the same effect.\\n\\nhe added that providing small- to medium-range planes manufactured by the same company played a central role in the government’s plan to rejuvenate iran’s air transportation fleet.\\n\\nakhoundi further emphasized that atr will start to deliver the planes that iran has purchased within the next few weeks.\\n\\nhe also stressed that iran'\n",
      "HYP: ' inised by the united day of\\n\\nthe said that the the-quality the-time- to by the first time. in few of in the world.s economy. make-ise the the.s office force..\\n\\n“- is, has that the the- be a the the first of have will been a the country few years.\\n\\nthe said said that the'\n",
      "[Epoch 4 | step  600/680 | global_step=2640] train_loss=5.1820  ppl=178.03  tok_acc=19.99%  tok/s=63,558\n",
      "Epoch 4 done | train_loss=5.1682  train_ppl=175.60  train_tok_acc=20.09%\n",
      "[Epoch 5 | step  150/680 | global_step=2870] train_loss=4.9551  ppl=141.90  tok_acc=21.60%  tok/s=63,434\n",
      "[Epoch 5 | step  300/680 | global_step=3020] train_loss=4.9375  ppl=139.41  tok_acc=21.75%  tok/s=63,400\n",
      "[Epoch 5 | step  450/680 | global_step=3170] train_loss=4.9189  ppl=136.86  tok_acc=21.91%  tok/s=63,514\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: ' shared understanding about the parks and open space that our city needs as we grow and recommends sustainable funding strategies to meet those needs.\\n\\nbut, livability is about more than the physical environment around us – it is also about the vibrancy of our city and its neighborhoods. my budget includes new funding for my arts shared prosperity agenda – more than $7 million to support artists, cultural equity'\n",
      "REF: ' understanding about the parks and open space that our city needs as we grow and recommends sustainable funding strategies to meet those needs.\\n\\nbut, livability is about more than the physical environment around us – it is also about the vibrancy of our city and its neighborhoods. my budget includes new funding for my arts shared prosperity agenda – more than $7 million to support artists, cultural equity,'\n",
      "HYP: ' with of the future and the to. we community. to a can. ourends our development.. our our in.\\n\\nthe the weers is a the than a future development. the. and’ a a the mostrantance of the community. our own.\\n research is a and and the new and with and, and than a1.. $ the. and and,'\n",
      "[Epoch 5 | step  600/680 | global_step=3320] train_loss=4.8994  ppl=134.21  tok_acc=22.09%  tok/s=63,551\n",
      "Epoch 5 done | train_loss=4.8908  train_ppl=133.07  train_tok_acc=22.17%\n",
      "[Epoch 6 | step  150/680 | global_step=3550] train_loss=4.7168  ppl=111.81  tok_acc=23.61%  tok/s=63,605\n",
      "[Epoch 6 | step  300/680 | global_step=3700] train_loss=4.7019  ppl=110.16  tok_acc=23.83%  tok/s=63,705\n",
      "[Epoch 6 | step  450/680 | global_step=3850] train_loss=4.6926  ppl=109.13  tok_acc=23.94%  tok/s=63,547\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: 'w0653b/rxdzz.txt.html http://u32.extabit.com/go/28du69vxbo4ix/?upld=1 http://d01.megashares.com/dl/22gofmh/rxdzz.txt http://minus.com/l3q9edct'\n",
      "REF: '0653b/rxdzz.txt.html http://u32.extabit.com/go/28du69vxbo4ix/?upld=1 http://d01.megashares.com/dl/22gofmh/rxdzz.txt http://minus.com/l3q9edctvs'\n",
      "HYP: 'w..21///a\\nxt.t.://wwwplo.org...org/c/c/xdddxd.cq=c0d://u3.coz...com/1/c/dd31xdx.htmlxt.://wwwor.com/dw...dd'\n",
      "[Epoch 6 | step  600/680 | global_step=4000] train_loss=4.6810  ppl=107.87  tok_acc=24.07%  tok/s=63,594\n",
      "Epoch 6 done | train_loss=4.6747  train_ppl=107.20  train_tok_acc=24.15%\n",
      "Guardado checkpoint (cada 3 epochs) -> gptmini_owt10k.pt\n",
      "[Epoch 7 | step  150/680 | global_step=4230] train_loss=4.5356  ppl=93.28  tok_acc=25.44%  tok/s=63,516\n",
      "[Epoch 7 | step  300/680 | global_step=4380] train_loss=4.5272  ppl=92.50  tok_acc=25.54%  tok/s=63,610\n",
      "[Epoch 7 | step  450/680 | global_step=4530] train_loss=4.5199  ppl=91.83  tok_acc=25.65%  tok/s=63,488\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: 'ictions?\\n\\nnow we can find out. an iphone app, our climate has just been released with contributors including notable sceptics such as richard lindzen, roy spencer and even the uk\\'s own lord christopher monckton. the first thing you see when you open the app is a top 10 list, featuring the \"top 10 climate tips you should know\\'. their number 1 tip argues'\n",
      "REF: '?\\n\\nnow we can find out. an iphone app, our climate has just been released with contributors including notable sceptics such as richard lindzen, roy spencer and even the uk\\'s own lord christopher monckton. the first thing you see when you open the app is a top 10 list, featuring the \"top 10 climate tips you should know\\'. their number 1 tip argues that'\n",
      "HYP: ',\\n\\nthe,’’ a,\\n example,, we iphone is been been a. aors, the ones&ic, as thesonsey, andce, john the former. chief...k,.\\n first time is can is you\\'re the phone, a little-.. you a mostthe\"\"\"\" can be\"\\n own of, is that'\n",
      "[Epoch 7 | step  600/680 | global_step=4680] train_loss=4.5146  ppl=91.34  tok_acc=25.69%  tok/s=63,553\n",
      "Epoch 7 done | train_loss=4.5110  train_ppl=91.01  train_tok_acc=25.75%\n",
      "[Epoch 8 | step  150/680 | global_step=4910] train_loss=4.4031  ppl=81.71  tok_acc=26.72%  tok/s=63,387\n",
      "[Epoch 8 | step  300/680 | global_step=5060] train_loss=4.4017  ppl=81.59  tok_acc=26.75%  tok/s=63,542\n",
      "[Epoch 8 | step  450/680 | global_step=5210] train_loss=4.4009  ppl=81.52  tok_acc=26.80%  tok/s=63,451\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: ' but they might contribute to changes of the global climate.”\\n\\nbuehler says that the technique used in the study has also been applied to study the mechanical properties of protein materials and polymers, whose structures are typically stabilized by hydrogen bonds. “for these structures, we found that the chemical conditions, for example, ph, ion concentration and ion type, are very important in'\n",
      "REF: ' they might contribute to changes of the global climate.”\\n\\nbuehler says that the technique used in the study has also been applied to study the mechanical properties of protein materials and polymers, whose structures are typically stabilized by hydrogen bonds. “for these structures, we found that the chemical conditions, for example, ph, ion concentration and ion type, are very important in affecting'\n",
      "HYP: ' it’ be to the to the new warming change\\n\\ntheirz,, the the climate is to the climate is been been used to the by effects effects of the and. thebi. but research are not usedized to the cells.\\nthe example experiments, the can that the cells cells are the example, areases areerg,, theional of are not important to the'\n",
      "[Epoch 8 | step  600/680 | global_step=5360] train_loss=4.3984  ppl=81.32  tok_acc=26.83%  tok/s=63,532\n",
      "Epoch 8 done | train_loss=4.3965  train_ppl=81.17  train_tok_acc=26.86%\n",
      "[Epoch 9 | step  150/680 | global_step=5590] train_loss=4.3315  ppl=76.06  tok_acc=27.44%  tok/s=63,634\n",
      "[Epoch 9 | step  300/680 | global_step=5740] train_loss=4.3283  ppl=75.81  tok_acc=27.52%  tok/s=63,611\n",
      "[Epoch 9 | step  450/680 | global_step=5890] train_loss=4.3258  ppl=75.62  tok_acc=27.56%  tok/s=63,604\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: ' ... samsung is locked in a battle with apple.\\n\\n\"intellectual property rights are an important cornerstone of the single market. however, such rights should not be misused when they are essential to implement industry standards, which bring huge benefits to businesses and consumers alike,\" the eu competition commissioner, joaquin almunia, said in statement.\\n\\napple and samsung,'\n",
      "REF: ' samsung is locked in a battle with apple.\\n\\n\"intellectual property rights are an important cornerstone of the single market. however, such rights should not be misused when they are essential to implement industry standards, which bring huge benefits to businesses and consumers alike,\" the eu competition commissioner, joaquin almunia, said in statement.\\n\\napple and samsung, the'\n",
      "HYP: ' i is a in the similar against the,\\n\\n\"itoisingity\" are not important part,\",\" the world market,\" the, the as are be be usederable, it are not to the the,,\" but are the amounts to the and the,\",\" said company said commission said saidan,o,-,, said. a.\\n\\n\"\\'s apple are the'\n",
      "[Epoch 9 | step  600/680 | global_step=6040] train_loss=4.3251  ppl=75.58  tok_acc=27.56%  tok/s=63,486\n",
      "Epoch 9 done | train_loss=4.3249  train_ppl=75.55  train_tok_acc=27.57%\n",
      "Guardado checkpoint (cada 3 epochs) -> gptmini_owt10k.pt\n",
      "[Epoch 10 | step  150/680 | global_step=6270] train_loss=4.2960  ppl=73.40  tok_acc=27.87%  tok/s=63,344\n",
      "[Epoch 10 | step  300/680 | global_step=6420] train_loss=4.2961  ppl=73.42  tok_acc=27.85%  tok/s=63,368\n",
      "[Epoch 10 | step  450/680 | global_step=6570] train_loss=4.2958  ppl=73.39  tok_acc=27.86%  tok/s=63,444\n",
      "— preview (LM, teacher-forced argmax) —\n",
      "CTX: 'zz0pcqi4l2k\\\\\" rel=\"nofollow\"> marsh is currently being held in the dallas county jail on $3,500 bail—a bit more than the estimated $1.20 that six nuggets would normally cost. at least he\\'ll get three hots and a cot.\\n\\ncomment #5 [permalink]\\n\\n... floridiot'\n",
      "REF: '0pcqi4l2k\\\\\" rel=\"nofollow\"> marsh is currently being held in the dallas county jail on $3,500 bail—a bit more than the estimated $1.20 that six nuggets would normally cost. at least he\\'ll get three hots and a cot.\\n\\ncomment #5 [permalink]\\n\\n... floridiot said'\n",
      "HYP: 'le.0x:ffaxx\\\\ohttp\"\"#als a available used in the form area jail. the1.000,outsand $ of than $ other $1,5 million the monthsmn were be be $\\n least $ would be a ofots to a half.\\n\\n\" #12 [permalink]\\n\\n...\\nal=='\n",
      "[Epoch 10 | step  600/680 | global_step=6720] train_loss=4.2919  ppl=73.11  tok_acc=27.90%  tok/s=63,362\n",
      "Epoch 10 done | train_loss=4.2906  train_ppl=73.01  train_tok_acc=27.92%\n"
     ]
    }
   ],
   "source": [
    "from src.model.gpt_model import *\n",
    "from src.training.main_loop import *\n",
    "\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "block_size = 256\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GPT2(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=block_size,  \n",
    "    n_layer=8,             \n",
    "    n_head=8,            \n",
    "    d_model=512,dropout=0.1,).to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Usando {torch.cuda.device_count()} GPUs con DataParallel\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    use_dataparallel = True\n",
    "\n",
    "def id2tok_fn(ids):\n",
    "    return tokenizer.decode(ids)\n",
    "\n",
    "\n",
    "history = train_gpt_lm(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,\n",
    "    base_lr=3e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=2000,\n",
    "    label_smoothing=0.1,\n",
    "    grad_clip=1.0,\n",
    "    device=device,\n",
    "    ckpt_path=\"gptmini_owt10k.pt\",\n",
    "    log_every=150,\n",
    "    preview_every=500,\n",
    "    id2tok_fn=id2tok_fn,\n",
    "    amp_enabled=True,\n",
    "    amp_dtype=\"fp16\",   \n",
    "    val_checking = False , save_ckpt_every = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T06:24:06.010198Z",
     "iopub.status.busy": "2025-11-18T06:24:06.009586Z",
     "iopub.status.idle": "2025-11-18T06:24:06.400582Z",
     "shell.execute_reply": "2025-11-18T06:24:06.399877Z",
     "shell.execute_reply.started": "2025-11-18T06:24:06.010172Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " whats your name? and if it's not an answer, you could see yourself in the future in order to find yourself.\n",
      "\n",
      "and that's not true.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.inference.generate_text import *\n",
    "\n",
    "prompt = \"whats your name?\"\n",
    "print(generate(model, tokenizer, prompt))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
